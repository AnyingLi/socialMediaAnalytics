{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['copy']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "%pylab inline\n",
    "aspirationList = ['dream','buy', 'favorite','purchase','goal', 'target', 'hope','aim','ideal','ambition', 'desire','wish','want','eager','love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brand = ['acura', 'audi','bmw', 'buick','cadillac', 'chevrolet', 'chrysler', 'dodge','ford','honda',\n",
    " 'hyundai',\n",
    " 'infiniti',\n",
    " 'kia',\n",
    " 'lincoln',\n",
    " 'mazda',\n",
    " 'mercedes',\n",
    " 'mercury',\n",
    " 'mitsubishi',\n",
    " 'nissan',\n",
    " 'pontiac',\n",
    " 'saturn',\n",
    " 'subaru',\n",
    " 'suzuki',\n",
    " 'toyota',\n",
    " 'volkswagen',\n",
    " 'volvo',\n",
    " 'lexus',\n",
    " 'jaguar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dictReplace(x):\n",
    "    for i in aspirationList:\n",
    "        my_regex = r\"\\b\" + re.escape(i) + r\"\\b\"\n",
    "        if re.search(my_regex, x, re.IGNORECASE):\n",
    "            x = x.replace(i,'aspiration')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edmunds = pd.read_csv(\"after_mapping3.csv\",sep=\"\\t\",encoding='utf-8')\n",
    "edmunds['text'] = edmunds['text'].str.lower()\n",
    "edmunds['text'] = edmunds['text'].map(dictReplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "comment2 = edmunds[\"text\"].tolist()\n",
    "\n",
    "comment = \" \".join(comment2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'one', u'beauty', u'bmw', u'bmw', u'many']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize = nltk.word_tokenize(comment)\n",
    "\n",
    "word_tokenize = [w for w in word_tokenize if w.isalpha()]\n",
    "\n",
    "no_stop = filter(lambda x: x not in stop_words, word_tokenize)\n",
    "\n",
    "no_stop[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car;4487\n",
      "bmw;4360\n",
      "acura;3157\n",
      "aspiration;2305\n",
      "cars;2166\n",
      "like;2136\n",
      "would;2131\n",
      "infiniti;2015\n",
      "one;1964\n",
      "audi;1888\n",
      "get;1622\n",
      "think;1454\n",
      "new;1301\n",
      "drive;1239\n",
      "better;1212\n",
      "much;1175\n",
      "lexus;1147\n",
      "good;1082\n",
      "even;1075\n",
      "well;994\n",
      "also;979\n",
      "driving;970\n",
      "really;945\n",
      "performance;924\n",
      "mercedes;921\n",
      "people;909\n",
      "luxury;870\n",
      "cadillac;869\n",
      "know;868\n",
      "price;807\n"
     ]
    }
   ],
   "source": [
    "cleaned_freq = nltk.FreqDist(no_stop)\n",
    "\n",
    "for word, frequency in cleaned_freq.most_common(30):\n",
    "    print('%s;%d' % (word, frequency)).encode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "c = defaultdict(dict)\n",
    "# make a copy dictionary to handle the case of term pair only count once for each post \n",
    "copy = defaultdict(dict)\n",
    "\n",
    "# insert default value 0 into array\n",
    "for i in brand:  \n",
    "    c[i] = 0\n",
    "# insert default value 0 into array\n",
    "for z in brand:\n",
    "    \n",
    "    copy[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2305"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_freq = {}\n",
    "aspir_count = 0\n",
    "for word, frequency in cleaned_freq.most_common(300):\n",
    "    if word in brand:\n",
    "        brand_freq[word] = frequency\n",
    "    if word == 'aspiration':\n",
    "        aspir_count = frequency\n",
    "aspir_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'acura': 258,\n",
       "             'audi': 128,\n",
       "             'bmw': 406,\n",
       "             'buick': 9,\n",
       "             'cadillac': 75,\n",
       "             'chevrolet': 15,\n",
       "             'chrysler': 5,\n",
       "             'dodge': 5,\n",
       "             'ford': 30,\n",
       "             'honda': 73,\n",
       "             'hyundai': 22,\n",
       "             'infiniti': 190,\n",
       "             'jaguar': 17,\n",
       "             'kia': 2,\n",
       "             'lexus': 123,\n",
       "             'lincoln': 8,\n",
       "             'mazda': 15,\n",
       "             'mercedes': 78,\n",
       "             'mercury': 0,\n",
       "             'mitsubishi': 3,\n",
       "             'nissan': 37,\n",
       "             'pontiac': 12,\n",
       "             'saturn': 1,\n",
       "             'subaru': 26,\n",
       "             'suzuki': 1,\n",
       "             'toyota': 65,\n",
       "             'volkswagen': 22,\n",
       "             'volvo': 35})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 10\n",
    "for sentence in comment2:\n",
    "    sentence=sentence.strip()\n",
    "    tokenized = nltk.word_tokenize(sentence)\n",
    "    tokenized = [w for w in tokenized if w.isalpha()]\n",
    "    no_stop = filter(lambda x: x not in stop_words, tokenized)\n",
    "    tokens=[token for token in no_stop if token!=u\"\"]\n",
    "    for pos,token in enumerate(tokens):\n",
    "        if token.lower() in brand:\n",
    "            start=max(0,pos-window_size)\n",
    "            end=min(len(tokens),pos+window_size+1) \n",
    "            aspire = tokens[start:end]\n",
    "            if 'aspiration' in aspire:\n",
    "                if c[token] == copy[token]:\n",
    "                    c[token] = c[token] + 1\n",
    "                        \n",
    "           \n",
    "    copy = c.copy()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268971"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acura 9.53629444467\n",
      "audi 7.91120261774\n",
      "bmw 10.8661093753\n",
      "buick 8.67943923558\n",
      "cadillac 10.0710792818\n",
      "chevrolet 11.4402194717\n",
      "chrysler 6.34186079411\n",
      "dodge 9.5647736567\n",
      "ford 13.2602543877\n",
      "honda 10.9490840857\n",
      "hyundai 11.4606484351\n",
      "infiniti 11.0030497947\n",
      "kia 8.04760266288\n",
      "lincoln 6.14159150588\n",
      "mazda 8.1792223326\n",
      "mercedes 9.88256092477\n",
      "mercury 0.0\n",
      "mitsubishi 14.0028286334\n",
      "nissan 9.10873170598\n",
      "pontiac 15.2204659059\n",
      "saturn 14.5862798265\n",
      "subaru 13.1339662507\n",
      "suzuki 5.07348863529\n",
      "toyota 13.7906645632\n",
      "volkswagen 8.47255857907\n",
      "volvo 10.0843416084\n",
      "lexus 12.5134257622\n",
      "jaguar 4.54984875321\n"
     ]
    }
   ],
   "source": [
    "lift = {}\n",
    "for i in brand:\n",
    "    try:    \n",
    "        lift[i] = (268971*c[i]*1.0)/(aspir_count*cleaned_freq[i]*1.0)\n",
    "    except:\n",
    "        print i\n",
    "    print i,lift[i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
